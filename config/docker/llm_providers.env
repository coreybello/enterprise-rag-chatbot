# Docker Environment Configuration for LLM Providers
# Copy this file to .env in your docker deployment directory

# === APPLICATION SETTINGS ===
APP_NAME=Enterprise RAG Chatbot
APP_VERSION=1.0.0
DEBUG=false
LOG_LEVEL=INFO

# === LLM PROVIDER CONFIGURATION ===
# Primary provider: vllm, openrouter, or unified
LLM_PROVIDER=unified
USE_UNIFIED_PROVIDER=true

# === FAILOVER AND LOAD BALANCING ===
FAILOVER_STRATEGY=auto
LOAD_BALANCING_STRATEGY=health_weighted
CIRCUIT_BREAKER_ENABLED=true
CIRCUIT_BREAKER_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT=60
PROVIDER_HEALTH_CHECK_INTERVAL=300

# === vLLM CONFIGURATION ===
VLLM_BASE_URL=http://vllm:8001
VLLM_MODEL_NAME=microsoft/DialoGPT-medium
VLLM_API_KEY=
VLLM_MAX_TOKENS=2048
VLLM_TEMPERATURE=0.7
VLLM_TIMEOUT=60
VLLM_MAX_RETRIES=3
VLLM_RETRY_DELAY=1.0
VLLM_CONNECT_TIMEOUT=10
VLLM_READ_TIMEOUT=60

# vLLM Advanced Parameters
VLLM_TOP_P=1.0
VLLM_PRESENCE_PENALTY=0.0
VLLM_FREQUENCY_PENALTY=0.0
VLLM_REPETITION_PENALTY=1.0
VLLM_STOP_TOKENS=
VLLM_BEST_OF=1
VLLM_USE_BEAM_SEARCH=false
VLLM_TOP_K=-1
VLLM_LENGTH_PENALTY=1.0
VLLM_MAX_MODEL_LENGTH=4096

# === OPENROUTER CONFIGURATION ===
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL_NAME=anthropic/claude-3-sonnet
OPENROUTER_MAX_TOKENS=4096
OPENROUTER_TEMPERATURE=0.7
OPENROUTER_TIMEOUT=120
OPENROUTER_MAX_RETRIES=3
OPENROUTER_RETRY_DELAY=1.0
OPENROUTER_HTTP_REFERER=https://github.com/enterprise-rag
OPENROUTER_SITE_URL=

# OpenRouter Advanced Parameters
OPENROUTER_TOP_P=1.0
OPENROUTER_PRESENCE_PENALTY=0.0
OPENROUTER_FREQUENCY_PENALTY=0.0
OPENROUTER_REPETITION_PENALTY=1.0
OPENROUTER_TOP_K=0
OPENROUTER_MIN_P=0.0
OPENROUTER_SEED=
OPENROUTER_LOGIT_BIAS={}
OPENROUTER_RESPONSE_FORMAT=
OPENROUTER_FALLBACK_MODELS=anthropic/claude-3-haiku,openai/gpt-3.5-turbo,meta-llama/llama-2-70b-chat
OPENROUTER_MAX_COST_PER_REQUEST=
OPENROUTER_COST_THRESHOLD_WARNING=
OPENROUTER_MODELS_CACHE_TTL=3600

# === RAG CONFIGURATION ===
VECTOR_DB_TYPE=chroma
VECTOR_DB_PATH=./data/vectordb
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHUNK_SIZE=512
CHUNK_OVERLAP=50
RETRIEVAL_TOP_K=5
SIMILARITY_THRESHOLD=0.7
MAX_CONTEXT_LENGTH=4000

# === API CONFIGURATION ===
API_HOST=0.0.0.0
API_PORT=8000
API_PREFIX=/api/v1
CORS_ORIGINS=*

# === SECURITY ===
SECRET_KEY=your-secret-key-change-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=30

# === CACHING ===
CACHE_TTL=3600
REDIS_URL=redis://redis:6379/0

# === MONITORING ===
ENABLE_METRICS=true
METRICS_ENDPOINT=/metrics